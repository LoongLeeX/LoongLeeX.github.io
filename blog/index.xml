<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogs on My New Hugo Site</title><link>http://example.com/blog/</link><description>Recent content in Blogs on My New Hugo Site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="http://example.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Aws Shadowsocket</title><link>http://example.com/blog/devops/awsshadowsocket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/devops/awsshadowsocket/</guid><description>keyword: AWS instance
创建key 用于 ssh 鉴权登陆
创建成功后，查看instance Details ip , ssh 登陆
chmod 400 [your pem path] ssh -i [your pem path] admin@your_ip 安装 shadowsocket docker
docker pull shadowsocks/shadowsocks-libev 指定 shadowsocks container 的端口，检查你的云服务是否开启了该端口 启动 docker instance 检查你的云服务是否开启了该端口
ps=&amp;lt;你的密码&amp;gt; port=&amp;lt;你的端口&amp;gt; docker run -e PASSWORD=$ps -p $port:8388 -p $port:8388/udp -d --restart always shadowsocks/shadowsocks-libev</description></item><item><title>Docker</title><link>http://example.com/blog/devops/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/devops/docker/</guid><description>keyword: Docker
What is the difference between Docker Desktop for Linux and Docker Engine?
Docker Desktop 和 Docker Engine 的区别
Install docker for debian
Install using the apt repository
# Add Docker&amp;#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg # Add the repository to Apt sources: echo \ &amp;#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.</description></item><item><title>Hadoop Architecture</title><link>http://example.com/blog/it/hadooparchitecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/it/hadooparchitecture/</guid><description>keyword: Hadoop, big data, AI, Architecture
Hadoop Architecture.
Apache Hadoop has the following three layers of Architecture.
Map-Reduce
YARN
HDFS
Map-Reduce 2. YARN 3. HDFS</description></item><item><title>Hadoop Architecture</title><link>http://example.com/blog/it/spark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/it/spark/</guid><description>keyword: Hadopp, big date ,AI, Architecture
Spark Architecture.</description></item><item><title>Installation</title><link>http://example.com/blog/my2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/my2/</guid><description>The following steps are here to help you initialize your new website. If you don&amp;rsquo;t know Hugo at all, we strongly suggest you learn more about it by following this great documentation for beginners.
Create your project Hugo provides a new command to create a new website.
hugo new site &amp;lt;new_project&amp;gt; Install the theme Install the Hugo-theme-learn theme by following this documentation
This theme&amp;rsquo;s repository is: https://github.com/matcornic/hugo-theme-learn.git
Alternatively, you can download the theme as .</description></item><item><title>Spark&amp;Hadoop</title><link>http://example.com/blog/it/sparkhadoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/it/sparkhadoop/</guid><description>keyword: Hadopp, Spark, big data, AI, Architecture
Case Study 1.
Case Study 2.
Case Study 3.
Case Study 4
Hadoop vs Spark: 使用场景 Hadoop 使用场景 Hadoop 适合以下场景：
大规模数据存储和处理: 当需要处理 PB 级别的数据时，Hadoop 的 HDFS 提供了一个可靠的存储解决方案。 高吞吐量的批处理作业: 对于需要高吞吐量而不是低延迟的长时间运行的批处理作业，Hadoop 是理想的选择。 成本效益的解决方案: 对于预算有限的项目，Hadoop 的开源特性使其成为一种成本效益高的选择。 兼容性和成熟的生态系统: Hadoop 已经成熟，拥有一个庞大的生态系统，适用于各种数据处理需求。 Spark 使用场景 Spark 适合以下场景：
快速数据处理和实时分析: 当需要快速处理数据或进行实时数据分析时，Spark 的内存计算功能提供了显著的速度优势。 迭代算法和机器学习: 对于需要迭代计算的机器学习算法，Spark 的内存计算比 Hadoop 更高效。 多种数据处理格式: 如果需要支持多种数据处理方式（批处理、流处理、交互式查询、机器学习），Spark 提供了一站式解决方案。 高级分析: Spark 支持 SQL 查询、流处理和复杂的分析，这些在 Hadoop MapReduce 中不那么容易实现。 根据项目需求和资源情况，可以选择适合的框架。在某些复杂的项目中，Hadoop 和 Spark 可以并行使用，以充分利用两者的优势。</description></item><item><title>不花钱 ！搭建Blog！</title><link>http://example.com/blog/hugogithubaction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/hugogithubaction/</guid><description>环境要求 git
开始盖别墅 安装hugo Hugo 官方安装：https://gohugo.io/installation/ 用hugo 命令 创建 后台工程，相当于系统后台，用于编辑Blog hugo new site MyBlog cd MyBlog git init # 安装主题 git submodule add git@github.com:cuisiting/ hugo-theme-learn.git themes/hugo-theme-learn # 指定主题 echo &amp;#34;theme = &amp;#39;hugo-theme-learn&amp;#39;&amp;#34; &amp;gt;&amp;gt; hugo.toml # 部署到本地查看一下 hugo server 至此，我们在本地电脑上，创建一个hugo 工程来存储blog 文件
小练习：增加一篇Blog，按如下的目录结构 添加文件 ，注意 需要创建 _index.md &amp;amp; 格式
RootProject └──content/ ├── _index.md └── 个人随想 ├── _index.md └── my_first.md 如上，我们在本地电脑上，创建一个 工程MyBlog 来存储blog 文件。
但是我们最终是需要将Blog 发布到 自由 、广大的互联网上。
现在我们用一种成本最小，但体验极佳的方式 将我们的Blog发布
创建2个仓库https://github.com/new
创建后台仓库工程 https://github.</description></item><item><title>设置HugoMarkdown图片大小</title><link>http://example.com/blog/%E8%AE%BE%E7%BD%AEhugomarkdown%E5%9B%BE%E7%89%87%E5%A4%A7%E5%B0%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.com/blog/%E8%AE%BE%E7%BD%AEhugomarkdown%E5%9B%BE%E7%89%87%E5%A4%A7%E5%B0%8F/</guid><description>https://gohugo.io/templates/render-hooks/</description></item></channel></rss>