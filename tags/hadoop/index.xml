<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Cuisiting</title>
    <link>https://cuisiting.github.io/tags/hadoop/</link>
    <description>Recent content in Hadoop on Cuisiting</description>
    <image>
      <title>Cuisiting</title>
      <url>https://cuisiting.github.io/images/papermod-cover.png</url>
      <link>https://cuisiting.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 11 Apr 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://cuisiting.github.io/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hadoop Architecture</title>
      <link>https://cuisiting.github.io/posts/cuisiting/hadooparchitecture/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://cuisiting.github.io/posts/cuisiting/hadooparchitecture/</guid>
      <description>keyword: Hadoop, big data, AI, Architecture
Hadoop Architecture.
Apache Hadoop has the following three layers of Architecture.
Map-Reduce
YARN
HDFS
Map-Reduce YARN HDFS </description>
    </item>
    <item>
      <title>Spark&amp;Hadoop</title>
      <link>https://cuisiting.github.io/posts/cuisiting/sparkhadoop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://cuisiting.github.io/posts/cuisiting/sparkhadoop/</guid>
      <description>keyword: Hadopp, Spark, big data, AI, Architecture
Case Study 1.
Case Study 2.
Case Study 3.
Case Study 4
Hadoop vs Spark: 使用场景 Hadoop 使用场景 Hadoop 适合以下场景：
大规模数据存储和处理: 当需要处理 PB 级别的数据时，Hadoop 的 HDFS 提供了一个可靠的存储解决方案。 高吞吐量的批处理作业: 对于需要高吞吐量而不是低延迟的长时间运行的批处理作业，Hadoop 是理想的选择。 成本效益的解决方案: 对于预算有限的项目，Hadoop 的开源特性使其成为一种成本效益高的选择。 兼容性和成熟的生态系统: Hadoop 已经成熟，拥有一个庞大的生态系统，适用于各种数据处理需求。 Spark 使用场景 Spark 适合以下场景：
快速数据处理和实时分析: 当需要快速处理数据或进行实时数据分析时，Spark 的内存计算功能提供了显著的速度优势。 迭代算法和机器学习: 对于需要迭代计算的机器学习算法，Spark 的内存计算比 Hadoop 更高效。 多种数据处理格式: 如果需要支持多种数据处理方式（批处理、流处理、交互式查询、机器学习），Spark 提供了一站式解决方案。 高级分析: Spark 支持 SQL 查询、流处理和复杂的分析，这些在 Hadoop MapReduce 中不那么容易实现。 根据项目需求和资源情况，可以选择适合的框架。在某些复杂的项目中，Hadoop 和 Spark 可以并行使用，以充分利用两者的优势。</description>
    </item>
  </channel>
</rss>
