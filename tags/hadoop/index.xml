<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hadoop on Hugo Theme Tailwind Example Site</title><link>https://cuisiting.github.io/tags/hadoop/</link><description>Recent content in Hadoop on Hugo Theme Tailwind Example Site</description><generator>Hugo</generator><language>en</language><copyright>Cuisiting</copyright><lastBuildDate>Tue, 30 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://cuisiting.github.io/tags/hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>Hadoop Architecture</title><link>https://cuisiting.github.io/posts/cuisiting/hadooparchitecture/</link><pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/hadooparchitecture/</guid><description>&lt;p>keyword: Hadoop, big data, AI, Architecture&lt;/p>
&lt;p>&lt;a href="https://www.cloudduggu.com/hadoop/architecture/" target="_blank" rel="noopener">Hadoop Architecture&lt;/a>
.&lt;/p>
&lt;p>Apache Hadoop has the following three layers of Architecture.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Map-Reduce&lt;/p>
&lt;/li>
&lt;li>
&lt;p>YARN&lt;/p>
&lt;/li>
&lt;li>
&lt;p>HDFS&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/hadoop_architecture.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;ol>
&lt;li>Map-Reduce&lt;/li>
&lt;/ol>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/hadoop_architecture_map_reduce.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;ol start="2">
&lt;li>
&lt;p>YARN&lt;br>



&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi//hadoop_architecture_yarn.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>HDFS&lt;br>



&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/hadoop_architecture_hdfs_1.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;br>



&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/hadoop_architecture_hdfs_2.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;br>



&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/hadoop_architecture_hdfs_3.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Spark&amp;Hadoop</title><link>https://cuisiting.github.io/posts/cuisiting/sparkhadoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/sparkhadoop/</guid><description>&lt;p>keyword: Hadopp, Spark, big data, AI, Architecture&lt;/p>
&lt;p>&lt;a href="https://developer.hpe.com/blog/performance-tuning-of-an-apache-kafkaspark-streaming-system-telecom-case/" target="_blank" rel="noopener">Case Study 1&lt;/a>
.&lt;/p>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/h_s_telecom_case.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;p>&lt;a href="https://avinash333.com/spark-architecture/" target="_blank" rel="noopener">Case Study 2&lt;/a>
.&lt;/p>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/h_s_avinash333.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;p>&lt;a href="https://www.databricks.com/blog/2016/06/22/apache-spark-key-terms-explained.html" target="_blank" rel="noopener">Case Study 3&lt;/a>
.&lt;/p>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/h_s_spark_key_terms.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;p>&lt;a href="https://medium.com/@dogukannulu/data-engineering-end-to-end-project-1-7a7be2a3671" target="_blank" rel="noopener">Case Study 4&lt;/a>
&lt;/p>
&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/bi/h_s_data_engineering_end_end.png"
 alt="image#width=50%" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p>
&lt;h2 id="hadoop-vs-spark-使用场景">Hadoop vs Spark: 使用场景&lt;/h2>
&lt;h3 id="hadoop-使用场景">Hadoop 使用场景&lt;/h3>
&lt;p>Hadoop 适合以下场景：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>大规模数据存储和处理&lt;/strong>:
&lt;ul>
&lt;li>当需要处理 PB 级别的数据时，Hadoop 的 HDFS 提供了一个可靠的存储解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>高吞吐量的批处理作业&lt;/strong>:
&lt;ul>
&lt;li>对于需要高吞吐量而不是低延迟的长时间运行的批处理作业，Hadoop 是理想的选择。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>成本效益的解决方案&lt;/strong>:
&lt;ul>
&lt;li>对于预算有限的项目，Hadoop 的开源特性使其成为一种成本效益高的选择。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>兼容性和成熟的生态系统&lt;/strong>:
&lt;ul>
&lt;li>Hadoop 已经成熟，拥有一个庞大的生态系统，适用于各种数据处理需求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="spark-使用场景">Spark 使用场景&lt;/h3>
&lt;p>Spark 适合以下场景：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>快速数据处理和实时分析&lt;/strong>:
&lt;ul>
&lt;li>当需要快速处理数据或进行实时数据分析时，Spark 的内存计算功能提供了显著的速度优势。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>迭代算法和机器学习&lt;/strong>:
&lt;ul>
&lt;li>对于需要迭代计算的机器学习算法，Spark 的内存计算比 Hadoop 更高效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>多种数据处理格式&lt;/strong>:
&lt;ul>
&lt;li>如果需要支持多种数据处理方式（批处理、流处理、交互式查询、机器学习），Spark 提供了一站式解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>高级分析&lt;/strong>:
&lt;ul>
&lt;li>Spark 支持 SQL 查询、流处理和复杂的分析，这些在 Hadoop MapReduce 中不那么容易实现。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>根据项目需求和资源情况，可以选择适合的框架。在某些复杂的项目中，Hadoop 和 Spark 可以并行使用，以充分利用两者的优势。&lt;/p></description></item><item><title>数据格式</title><link>https://cuisiting.github.io/posts/cuisiting/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/</link><pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/</guid><description>&lt;p>&lt;strong>二进制数据格式&lt;/strong>：&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: left">数据格式&lt;/th>
 &lt;th style="text-align: left">特点&lt;/th>
 &lt;th style="text-align: left">适用场景&lt;/th>
 &lt;th style="text-align: left">使用服务/应用程序&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: left">Avro&lt;/td>
 &lt;td style="text-align: left">二进制格式，高性能，模式定义&lt;/td>
 &lt;td style="text-align: left">大数据处理，分布式系统&lt;/td>
 &lt;td style="text-align: left">Apache Hadoop，Kafka&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">Protocol Buffers&lt;/td>
 &lt;td style="text-align: left">二进制格式，高性能，代码生成&lt;/td>
 &lt;td style="text-align: left">分布式系统，网络通信，高性能数据交换&lt;/td>
 &lt;td style="text-align: left">gRPC，Google APIs&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">MessagePack&lt;/td>
 &lt;td style="text-align: left">二进制格式，紧凑，多语言支持&lt;/td>
 &lt;td style="text-align: left">数据存储，通信，高性能应用程序&lt;/td>
 &lt;td style="text-align: left">Redis，MessagePack-RPC&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">BSON&lt;/td>
 &lt;td style="text-align: left">二进制JSON扩展，高性能，数据类型支持&lt;/td>
 &lt;td style="text-align: left">NoSQL数据库，MongoDB数据交换&lt;/td>
 &lt;td style="text-align: left">MongoDB&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>文本数据格式&lt;/strong>：&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: left">数据格式&lt;/th>
 &lt;th style="text-align: left">特点&lt;/th>
 &lt;th style="text-align: left">适用场景&lt;/th>
 &lt;th style="text-align: left">使用服务/应用程序&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: left">JSON&lt;/td>
 &lt;td style="text-align: left">文本格式，易于阅读，易于编写&lt;/td>
 &lt;td style="text-align: left">Web应用程序，API，配置文件&lt;/td>
 &lt;td style="text-align: left">RESTful API，JavaScript&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">XML&lt;/td>
 &lt;td style="text-align: left">标记语言，支持嵌套，复杂结构&lt;/td>
 &lt;td style="text-align: left">数据交换，配置文件，复杂文档&lt;/td>
 &lt;td style="text-align: left">SOAP，RSS，配置文件&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">YAML&lt;/td>
 &lt;td style="text-align: left">人类可读，简洁语法，易于编写&lt;/td>
 &lt;td style="text-align: left">配置文件，人类可读数据交换&lt;/td>
 &lt;td style="text-align: left">Docker Compose，Ansible&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>其他数据格式&lt;/strong>：&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: left">数据格式&lt;/th>
 &lt;th style="text-align: left">特点&lt;/th>
 &lt;th style="text-align: left">适用场景&lt;/th>
 &lt;th style="text-align: left">使用服务/应用程序&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: left">TOML&lt;/td>
 &lt;td style="text-align: left">人类可读，简单，易于编写&lt;/td>
 &lt;td style="text-align: left">配置文件，人类可读数据交换&lt;/td>
 &lt;td style="text-align: left">Rust，Cargo配置文件&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">CSV&lt;/td>
 &lt;td style="text-align: left">文本格式，表格数据，易于导入导出&lt;/td>
 &lt;td style="text-align: left">数据导入导出，电子表格&lt;/td>
 &lt;td style="text-align: left">Microsoft Excel，Pandas&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">HTML&lt;/td>
 &lt;td style="text-align: left">网页标记语言，网页内容描述&lt;/td>
 &lt;td style="text-align: left">网页制作，数据抓取，内容展示&lt;/td>
 &lt;td style="text-align: left">Web浏览器，网页编辑器&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: left">EDN&lt;/td>
 &lt;td style="text-align: left">可扩展数据表示，Clojure相关&lt;/td>
 &lt;td style="text-align: left">Clojure编程，数据交换&lt;/td>
 &lt;td style="text-align: left">Clojure，Datomic&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table></description></item><item><title>大数据</title><link>https://cuisiting.github.io/posts/cuisiting/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link><pubDate>Thu, 11 Jan 2024 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/%E5%A4%A7%E6%95%B0%E6%8D%AE/</guid><description>&lt;p>


&lt;div class="not-prose">
&lt;figure>
 &lt;img src="https://cuisiting.github.io/drawio/big_data_1.svg"
 alt="d#width=50%&amp;amp;height=100" 
 loading="lazy"
 width="50%"
 >
 &lt;/figure>&lt;/div>
&lt;/p></description></item></channel></rss>