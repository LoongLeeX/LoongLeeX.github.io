<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Token on Hugo Theme Tailwind Example Site</title><link>https://cuisiting.github.io/tags/token/</link><description>Recent content in Token on Hugo Theme Tailwind Example Site</description><generator>Hugo</generator><language>en</language><copyright>Cuisiting</copyright><lastBuildDate>Sun, 10 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://cuisiting.github.io/tags/token/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM, What's the Token?</title><link>https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/</link><pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/</guid><description>&lt;h1 id="token--vs-word">Token vs Word&lt;/h1>
&lt;h2 id="summary">Summary:&lt;/h2>
&lt;p>Summary OpenAi&lt;br>
&lt;a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them" target="_blank" rel="noopener">What are tokens and how to count them? | OpenAI Help Center&lt;/a>
&lt;/p>
&lt;pre tabindex="0">&lt;code>- 1 token ~= 4 chars in English
- 1 token ~= ¾ words
- 100 tokens ~= 75 words
Or

- 1-2 sentence ~= 30 tokens
- 1 paragraph ~= 100 tokens
- 1,500 words ~= 2048 tokens
	
&lt;/code>&lt;/pre>&lt;h2 id="why-need-token">Why need Token?&lt;/h2>
&lt;p>在大型语言模型（如GPT系列）中，&lt;br>
&lt;strong>&amp;ldquo;Token&amp;quot;通常指的是文本处理的基本单位&lt;/strong>。&lt;br>
在传统的文本处理中，我们可能会将文本&lt;strong>分割&lt;/strong>成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，&amp;ldquo;Token&amp;quot;可以是更小的单位，如&lt;strong>字（characters）&lt;/strong>、&lt;strong>词根&lt;/strong>、甚至是&lt;strong>词的&lt;/strong>一部分，这取决于所使用的分词方法（tokenization method）。&lt;/p></description></item></channel></rss>