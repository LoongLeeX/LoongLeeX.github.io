<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM on Hugo Theme Tailwind Example Site</title><link>https://cuisiting.github.io/tags/llm/</link><description>Recent content in LLM on Hugo Theme Tailwind Example Site</description><generator>Hugo 0.125.2</generator><language>en</language><copyright>Cuisiting</copyright><lastBuildDate>Sun, 10 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://cuisiting.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM, What's the Token?</title><link>https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/</link><pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/</guid><description>Token vs Word Summary: Summary OpenAi
What are tokens and how to count them? | OpenAI Help Center - 1 token ~= 4 chars in English - 1 token ~= ¾ words - 100 tokens ~= 75 words Or - 1-2 sentence ~= 30 tokens - 1 paragraph ~= 100 tokens - 1,500 words ~= 2048 tokens Why need Token? 在大型语言模型（如GPT系列）中，
&amp;ldquo;Token&amp;quot;通常指的是文本处理的基本单位。
在传统的文本处理中，我们可能会将文本分割成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，&amp;ldquo;Token&amp;quot;可以是更小的单位，如字（characters）、词根、甚至是词的一部分，这取决于所使用的分词方法（tokenization method）。
分词方法将原始文本分解为一系列的token，这些token随后被模型用于训练和生成文本。这一过程允许模型理解和生成包括多种语言在内的复杂文本，因为它可以捕捉到词汇的细微差别、语法结构和语境意义。</description></item><item><title>LangChain</title><link>https://cuisiting.github.io/posts/cuisiting/langchain/</link><pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate><guid>https://cuisiting.github.io/posts/cuisiting/langchain/</guid><description>LangChain 还包括一些组件，可让 LLM 无需重新训练即可访问新的数据集。 LLM 擅长在常规上下文下对提示做出响应，但在未接受过训练的特定领域却很吃力。_提示_是人们寻求 LLM 回复时所用的查询。例如，LLM 可以通过提供估算值来回答计算机成本问题。但是，它无法列出贵公司销售的特定计算机型号的价格。 LangChain LangChain is a framework for developing applications powered by language models. It enables applications that:
Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.) Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)
Build context-aware reasoning applications AWS explain https://aws.</description></item></channel></rss>