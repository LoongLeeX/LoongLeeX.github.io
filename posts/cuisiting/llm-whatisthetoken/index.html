<!doctype html><html lang=en dir=ltr><head><title>LLM, What's the Token? :: Hugo Theme Tailwind Example Site - Example site for hugo-theme-tailwind</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='Token vs Word Summary: Summary OpenAi
What are tokens and how to count them? | OpenAI Help Center - 1 token ~= 4 chars in English - 1 token ~= ¾ words - 100 tokens ~= 75 words Or - 1-2 sentence ~= 30 tokens - 1 paragraph ~= 100 tokens - 1,500 words ~= 2048 tokens Why need Token? 在大型语言模型（如GPT系列）中，
&ldquo;Token"通常指的是文本处理的基本单位。
在传统的文本处理中，我们可能会将文本分割成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，&ldquo;Token"可以是更小的单位，如字（characters）、词根、甚至是词的一部分，这取决于所使用的分词方法（tokenization method）。
'><meta name=keywords content="hugo,tailwind,tailwindcss,hugo theme,hugo theme tailwind"><meta name=robots content="noodp"><meta property="og:url" content="https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/"><meta property="og:site_name" content="Hugo Theme Tailwind Example Site"><meta property="og:title" content="LLM, What's the Token?"><meta property="og:description" content='Token vs Word Summary: Summary OpenAi
What are tokens and how to count them? | OpenAI Help Center - 1 token ~= 4 chars in English - 1 token ~= ¾ words - 100 tokens ~= 75 words Or - 1-2 sentence ~= 30 tokens - 1 paragraph ~= 100 tokens - 1,500 words ~= 2048 tokens Why need Token? 在大型语言模型（如GPT系列）中，
“Token"通常指的是文本处理的基本单位。
在传统的文本处理中，我们可能会将文本分割成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，“Token"可以是更小的单位，如字（characters）、词根、甚至是词的一部分，这取决于所使用的分词方法（tokenization method）。'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-10T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-10T00:00:00+00:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Token"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM, What's the Token?"><meta name=twitter:description content='Token vs Word Summary: Summary OpenAi
What are tokens and how to count them? | OpenAI Help Center - 1 token ~= 4 chars in English - 1 token ~= ¾ words - 100 tokens ~= 75 words Or - 1-2 sentence ~= 30 tokens - 1 paragraph ~= 100 tokens - 1,500 words ~= 2048 tokens Why need Token? 在大型语言模型（如GPT系列）中，
“Token"通常指的是文本处理的基本单位。
在传统的文本处理中，我们可能会将文本分割成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，“Token"可以是更小的单位，如字（characters）、词根、甚至是词的一部分，这取决于所使用的分词方法（tokenization method）。'><link rel=canonical href=https://cuisiting.github.io/posts/cuisiting/llm-whatisthetoken/><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=/css/index.min.0ad2ef81fbf5e611b871854217e425d97666607d70bef039275d5cefb99bc22f.css></head><body class="w-full bg-slate-50 dark:bg-gray-800"><header class="flex flex-none justify-center z-10"><div class="flex flex-row gap justify-between w-full max-w-4xl lg:max-w-5xl h-12 mt-3"><div class="flex-none ml-2 md:ml-0"><a href=/><img class="h-12 w-12 rounded-full object-cover bg-gray-100" src=https://placehold.co/512/webp alt=logo></a></div><div class=flex-1></div><div class=flex-none></div><div class="flex-none mx-1"></div><div class="darkmode-toggle flex flex-none mr-2 md:mr-0"><label for=darkmode-toggle class="flex items-center px-3 cursor-pointer rounded-full bg-gray-100 dark:bg-gray-600" title="Toggle dark mode"><input name=darkmode-toggle id=darkmode-toggle type=checkbox class="sr-only peer" aria-label="Toggle dark mode"><div class="group flex flex-row gap-1 justify-center h-8 px-1 rounded-full bg-white dark:bg-gray-700"><i class="h-6 w-6 flex-none rounded-full bg-yellow-400 place-self-center peer-checked:group-[]:invisible"><svg class="icon icon-tabler icon-tabler-brightness-down" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-3 0a3 3 0 106 0 3 3 0 10-6 0"/><path d="M12 5v.01"/><path d="M17 7v.01"/><path d="M19 12v.01"/><path d="M17 17v.01"/><path d="M12 19v.01"/><path d="M7 17v.01"/><path d="M5 12v.01"/><path d="M7 7v.01"/></svg>
</i><i class="h-6 w-6 flex-none rounded-full place-self-center invisible peer-checked:group-[]:visible"><svg class="icon icon-tabler icon-tabler-moon-stars" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/><path d="M17 4a2 2 0 002 2 2 2 0 00-2 2 2 2 0 00-2-2 2 2 0 002-2"/><path d="M19 11h2m-1-1v2"/></svg></i></div></label></div></div></header><main class="flex flex-auto justify-center"><div class="w-full max-w-4xl lg:max-w-5xl"><div class="flex flex-col gap-y-3 p-6 mt-6 mx-2 md:mx-0 rounded-lg shadow-md bg-white dark:bg-gray-700"><h1 class="text-4xl font-semibold text-slate-800 dark:text-slate-100"><a href=/posts/cuisiting/llm-whatisthetoken/>LLM, What&rsquo;s the Token?</a></h1><ul class="flex flex-row flex-wrap text-slate-500 dark:text-slate-300"><li><a href=/categories/tools/ class="text-sm mr-2 px-2 py-1 rounded border border-emerald-800 bg-emerald-800 text-slate-50">tools</a></li><li><a href=/tags/llm/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>LLM</span></a></li><li><a href=/tags/token/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Token</span></a></li></ul><div class="flex flex-col gap-y-1 md:flex-row md:gap-y-0 md:gap-x-4 text-slate-500 dark:text-slate-300"><div class="flex flex-row text-base gap-x-1"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-calendar" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 7a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2V7z"/><path d="M16 3v4"/><path d="M8 3v4"/><path d="M4 11h16"/><path d="M11 15h1"/><path d="M12 15v3"/></svg>
</i><time datetime=2024-03-10T00:00:00+00:00>2024-03-10</time></div><div class="flex flex-row text-base gap-x-1"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-hourglass-high" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M6.5 7h11"/><path d="M6 20v-2a6 6 0 1112 0v2a1 1 0 01-1 1H7a1 1 0 01-1-1z"/><path d="M6 4v2a6 6 0 1012 0V4a1 1 0 00-1-1H7A1 1 0 006 4z"/></svg>
</i><span>One minute to read</span></div></div><section class="prose prose-slate dark:prose-invert w-full max-w-4xl lg:max-w-5xl mt-6"><h2>Table of Contents</h2><aside><nav id=TableOfContents><ul><li><a href=#summary>Summary:</a></li><li><a href=#why-need-token>Why need Token?</a></li></ul></nav></aside></section><article class="mt-6 w-full max-w-4xl lg:max-w-5xl prose prose-slate dark:prose-invert prose-quoteless post-content"><h1 id=token--vs-word>Token vs Word</h1><h2 id=summary>Summary:</h2><p>Summary OpenAi<br><a href=https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them target=_blank rel=noopener>What are tokens and how to count them? | OpenAI Help Center</a></p><pre tabindex=0><code>- 1 token ~= 4 chars in English
- 1 token ~= ¾ words
- 100 tokens ~= 75 words
Or

- 1-2 sentence ~= 30 tokens
- 1 paragraph ~= 100 tokens
- 1,500 words ~= 2048 tokens
	
</code></pre><h2 id=why-need-token>Why need Token?</h2><p>在大型语言模型（如GPT系列）中，<br><strong>&ldquo;Token"通常指的是文本处理的基本单位</strong>。<br>在传统的文本处理中，我们可能会将文本<strong>分割</strong>成词（words）或者句子作为基本的处理单位。然而，在现代的大型语言模型中，&ldquo;Token"可以是更小的单位，如<strong>字（characters）</strong>、<strong>词根</strong>、甚至是<strong>词的</strong>一部分，这取决于所使用的分词方法（tokenization method）。</p><p>分词方法将原始文本分解为一系列的token，这些token随后被模型用于训练和生成文本。这一过程允许模型理解和生成包括多种语言在内的复杂文本，因为它可以捕捉到词汇的细微差别、语法结构和语境意义。</p><p><div class=not-prose><figure><img src=/bi/llm_token_1.png alt="image#width=50%" loading=lazy width=50%></figure></div><br><div class=not-prose><figure><img src=/bi/llm_token_2.png alt="image#width=50%" loading=lazy width=50%></figure></div></p></article></div></div></main><footer class="flex flex-none justify-center"><section class="flex flex-col md:flex-row mx-2 md:mx-0 gap-2 md:gap-0 justify-between w-full max-w-4xl lg:max-w-5xl py-6 text-slate-500 dark:text-slate-300"><div class="flex flex-row"></div><div class=grow></div><div class="flex flex-row"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-copyright" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-9 0a9 9 0 1018 0A9 9 0 103 12"/><path d="M14 9.75a3.016 3.016.0 00-4.163.173 2.993 2.993.0 000 4.154A3.016 3.016.0 0014 14.25"/></svg>
</i>2023 - 2024 Cuisiting</div><div class="flex flex-row"><span class="ml-0 pl-0 md:ml-2 md:pl-2 border-l-0 md:border-l border-slate-300 dark:border-slate-400">Powered by <a href=https://gohugo.io target=_blank rel=noopener class=underline>Hugo</a> <span class=text-red-600>&#9829;</span> <a href=https://github.com/tomowang/hugo-theme-tailwind target=_blank rel=noopener class=underline>Tailwind</a></span></div></section></footer><script src=/main.min.c6372b6836971865bd94bfde974748aca8415824a2facab6ccd66a87384bfacb.js></script><div class="hidden top-1 right-1" id=code-copy><i class="h-6 w-6 block"><svg class="icon icon-tabler icon-tabler-copy" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 7m0 2.667A2.667 2.667.0 019.667 7h8.666A2.667 2.667.0 0121 9.667v8.666A2.667 2.667.0 0118.333 21H9.667A2.667 2.667.0 017 18.333z"/><path d="M4.012 16.737A2.005 2.005.0 013 15V5c0-1.1.9-2 2-2h10c.75.0 1.158.385 1.5 1"/></svg></i></div><div class="hidden top-1 right-1" id=code-copy-done><i class="h-6 w-6 block"><svg class="icon icon-tabler icon-tabler-check" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12l5 5L20 7"/></svg></i></div><script src=/code-copy.min.4be95a7068ec721962fd0df64ce1c8673df8035fde465874f1e6e67e2aac7f71.js></script></body></html>